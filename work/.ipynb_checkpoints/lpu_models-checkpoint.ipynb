{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99ed3659-38bc-4fa8-9612-b433e3cc2c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    @author:\n",
    "        - Leonardo Lo Schiavo\n",
    "    @affiliation:\n",
    "        - IMDEA Networks institute\n",
    "'''\n",
    "import torch, os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14d89ca4-63c0-4cf6-9c60-e2d92171912f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    @author:\n",
    "        - Leonardo Lo Schiavo\n",
    "    @affiliation:\n",
    "        - IMDEA Networks institute\n",
    "'''\n",
    "class Predictor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size, hidden_size, nonlin=F.relu, norm_in=False):\n",
    "\n",
    "        super(Predictor, self).__init__()\n",
    "\n",
    "        if norm_in:\n",
    "            self.in_fn = nn.BatchNorm1d(input_size, affine=False)\n",
    "        else:\n",
    "            self.in_fn = lambda x: x\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.nonlin = nonlin\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        inp = self.in_fn(X)\n",
    "        h1 = self.nonlin(self.fc1(inp))\n",
    "        h2 = self.nonlin(self.fc2(h1))\n",
    "        out = self.fc3(h2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eff2ab8-1b00-42c7-a264-82ce32fe8e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    @author:\n",
    "        - Leonardo Lo Schiavo\n",
    "    @affiliation:\n",
    "        - IMDEA Networks institute\n",
    "'''\n",
    "class LPUModels:\n",
    "\n",
    "    def __init__(self):\n",
    "        # Dataset parameters\n",
    "        self.max_snr = 30.0\n",
    "        self.max_mcs = 27\n",
    "        self.max_total_bits = 295680\n",
    "        self.max_prbs = 250\n",
    "\n",
    "        # LPU models parameters\n",
    "        self.input_size = 3\n",
    "        self.output_size = 1\n",
    "        self.hidden_size = 128\n",
    "\n",
    "        # Import max and min values for the inputs (only GPU power model)\n",
    "        self.max_gpu_power = np.load('/home/jovyan/data/max_power_gpu.npy')\n",
    "        self.min_gpu_power = np.load('/home/jovyan/data/min_power_gpu.npy')\n",
    "\n",
    "        # Load the model weights and set the model to inference mode\n",
    "        self.predictor_time_cpu = Predictor(self.input_size, self.output_size, self.hidden_size)\n",
    "        self.predictor_time_cpu.load_state_dict(torch.load('/home/jovyan/data/predictor_time_cpu.pyt', map_location=\"cpu\"))\n",
    "        self.predictor_time_cpu.eval()\n",
    "        self.predictor_time_gpu = Predictor(self.input_size, self.output_size, self.hidden_size)\n",
    "        self.predictor_time_gpu.load_state_dict(torch.load('/home/jovyan/data/predictor_time_gpu.pyt', map_location=\"cpu\"))\n",
    "        self.predictor_time_gpu.eval()\n",
    "        self.predictor_power_cpu = Predictor(self.input_size, self.output_size, self.hidden_size)\n",
    "        self.predictor_power_cpu.load_state_dict(torch.load('/home/jovyan/data/predictor_power_cpu.pyt', map_location=\"cpu\"))\n",
    "        self.predictor_power_cpu.eval()\n",
    "        self.predictor_power_gpu = Predictor(self.input_size, self.output_size, self.hidden_size)\n",
    "        self.predictor_power_gpu.load_state_dict(torch.load('/home/jovyan/data/predictor_power_gpu.pyt', map_location=\"cpu\"))\n",
    "        self.predictor_power_gpu.eval()\n",
    "\n",
    "\n",
    "    def estimate_service_time(self, snr, mcs, prbs, total_bits):\n",
    "        # Normalize the inputs and format them for PyTorch\n",
    "        power_inputs = []\n",
    "        power_inputs.append(snr / self.max_snr)\n",
    "        power_inputs.append(mcs / self.max_mcs)\n",
    "        power_inputs.append(prbs / self.max_prbs)\n",
    "        power_inputs = torch.Tensor(power_inputs)\n",
    "\n",
    "        time_inputs = []\n",
    "        time_inputs.append(snr / self.max_snr)\n",
    "        time_inputs.append(mcs / self.max_mcs)\n",
    "        time_inputs.append(total_bits / self.max_total_bits)\n",
    "        time_inputs = torch.Tensor(time_inputs)\n",
    "        # Run the model in inference mode\n",
    "        power_cpu = self.predictor_power_cpu(power_inputs).detach().numpy()\n",
    "        time_cpu = float(self.predictor_time_cpu(time_inputs).detach().numpy())\n",
    "        energy_cpu = float(power_cpu * time_cpu)\n",
    "\n",
    "        power_gpu = self.predictor_power_gpu(power_inputs).detach().numpy() * (self.max_gpu_power - self.min_gpu_power) + self.min_gpu_power\n",
    "        time_gpu = float(self.predictor_time_gpu(time_inputs).detach().numpy())\n",
    "        energy_gpu = float(power_gpu * time_gpu)\n",
    "\n",
    "        return time_cpu, energy_cpu, time_gpu, energy_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa043955-8785-4ca7-9d3f-1c0f94462056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_92/1786070879.py:55: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  time_cpu = float(self.predictor_time_cpu(time_inputs).detach().numpy())\n",
      "/tmp/ipykernel_92/1786070879.py:56: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  energy_cpu = float(power_cpu * time_cpu)\n",
      "/tmp/ipykernel_92/1786070879.py:59: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  time_gpu = float(self.predictor_time_gpu(time_inputs).detach().numpy())\n",
      "/tmp/ipykernel_92/1786070879.py:60: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  energy_gpu = float(power_gpu * time_gpu)\n",
      "/tmp/ipykernel_92/711099665.py:15: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, tmp_df], ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    @author:\n",
    "        - Leonardo Lo Schiavo\n",
    "    @affiliation:\n",
    "        - IMDEA Networks institute\n",
    "'''\n",
    "input_file = \"/home/jovyan/data/trace_40BS.csv\"\n",
    "\n",
    "# Load Trace\n",
    "trace_df = pd.read_csv(input_file, sep=\",\", header=0)\n",
    "trace_df.value_counts()\n",
    "\n",
    "# Create an instance of LPU Models\n",
    "lpu_models = LPUModels()\n",
    "\n",
    "# Run inference for each request within the trace\n",
    "results_df = pd.DataFrame(columns = ['t_cpu', 'e_cpu', 't_gpu', 'e_gpu'])\n",
    "for index, row in trace_df.iterrows():\n",
    "    t_cpu, e_cpu, t_gpu, e_gpu = lpu_models.estimate_service_time(row['SNR'], row['MCS'], row['PRBs'], row['TBS'])\n",
    "    tmp_df = pd.DataFrame([[t_cpu, e_cpu, t_gpu, e_gpu]], columns=['t_cpu', 'e_cpu', 't_gpu', 'e_gpu'])\n",
    "    results_df = pd.concat([results_df, tmp_df], ignore_index = True)\n",
    "\n",
    "print(results_df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d62115c-b7dc-42b7-ac08-55099aec7192",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
