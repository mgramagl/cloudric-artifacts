{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99ed3659-38bc-4fa8-9612-b433e3cc2c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    @author:\n",
    "        - Leonardo Lo Schiavo\n",
    "    @affiliation:\n",
    "        - IMDEA Networks institute\n",
    "'''\n",
    "import torch, os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14d89ca4-63c0-4cf6-9c60-e2d92171912f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    @author:\n",
    "        - Leonardo Lo Schiavo\n",
    "    @affiliation:\n",
    "        - IMDEA Networks institute\n",
    "'''\n",
    "class Predictor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size, hidden_size, nonlin=F.relu, norm_in=False):\n",
    "\n",
    "        super(Predictor, self).__init__()\n",
    "\n",
    "        if norm_in:\n",
    "            self.in_fn = nn.BatchNorm1d(input_size, affine=False)\n",
    "        else:\n",
    "            self.in_fn = lambda x: x\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.nonlin = nonlin\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        inp = self.in_fn(X)\n",
    "        h1 = self.nonlin(self.fc1(inp))\n",
    "        h2 = self.nonlin(self.fc2(h1))\n",
    "        out = self.fc3(h2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eff2ab8-1b00-42c7-a264-82ce32fe8e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    @author:\n",
    "        - Leonardo Lo Schiavo\n",
    "    @affiliation:\n",
    "        - IMDEA Networks institute\n",
    "'''\n",
    "class LPUModels:\n",
    "\n",
    "    def __init__(self):\n",
    "        # Dataset parameters\n",
    "        self.max_snr = 30.0\n",
    "        self.max_mcs = 27\n",
    "        self.max_total_bits = 295680\n",
    "        self.max_prbs = 250\n",
    "\n",
    "        # LPU models parameters\n",
    "        self.input_size = 3\n",
    "        self.output_size = 1\n",
    "        self.hidden_size = 128\n",
    "\n",
    "        # Import max and min values for the inputs (only GPU power model)\n",
    "        self.max_gpu_power = np.load('/home/jovyan/data/max_power_gpu.npy')\n",
    "        self.min_gpu_power = np.load('/home/jovyan/data/min_power_gpu.npy')\n",
    "\n",
    "        # Load the model weights and set the model to inference mode\n",
    "        self.predictor_time_cpu = Predictor(self.input_size, self.output_size, self.hidden_size)\n",
    "        self.predictor_time_cpu.load_state_dict(torch.load('/home/jovyan/data/predictor_time_cpu.pyt', map_location=\"cpu\"))\n",
    "        self.predictor_time_cpu.eval()\n",
    "        self.predictor_time_gpu = Predictor(self.input_size, self.output_size, self.hidden_size)\n",
    "        self.predictor_time_gpu.load_state_dict(torch.load('/home/jovyan/data/predictor_time_gpu.pyt', map_location=\"cpu\"))\n",
    "        self.predictor_time_gpu.eval()\n",
    "        self.predictor_power_cpu = Predictor(self.input_size, self.output_size, self.hidden_size)\n",
    "        self.predictor_power_cpu.load_state_dict(torch.load('/home/jovyan/data/predictor_power_cpu.pyt', map_location=\"cpu\"))\n",
    "        self.predictor_power_cpu.eval()\n",
    "        self.predictor_power_gpu = Predictor(self.input_size, self.output_size, self.hidden_size)\n",
    "        self.predictor_power_gpu.load_state_dict(torch.load('/home/jovyan/data/predictor_power_gpu.pyt', map_location=\"cpu\"))\n",
    "        self.predictor_power_gpu.eval()\n",
    "\n",
    "\n",
    "    def estimate_service_time(self, snr, mcs, prbs, total_bits):\n",
    "        # Normalize the inputs and format them for PyTorch\n",
    "        power_inputs = []\n",
    "        power_inputs.append(snr / self.max_snr)\n",
    "        power_inputs.append(mcs / self.max_mcs)\n",
    "        power_inputs.append(prbs / self.max_prbs)\n",
    "        power_inputs = torch.Tensor(power_inputs)\n",
    "\n",
    "        time_inputs = []\n",
    "        time_inputs.append(snr / self.max_snr)\n",
    "        time_inputs.append(mcs / self.max_mcs)\n",
    "        time_inputs.append(total_bits / self.max_total_bits)\n",
    "        time_inputs = torch.Tensor(time_inputs)\n",
    "        # Run the model in inference mode\n",
    "        power_cpu = self.predictor_power_cpu(power_inputs).detach().numpy()\n",
    "        time_cpu = float(self.predictor_time_cpu(time_inputs).detach().numpy())\n",
    "        energy_cpu = float(power_cpu * time_cpu)\n",
    "\n",
    "        power_gpu = self.predictor_power_gpu(power_inputs).detach().numpy() * (self.max_gpu_power - self.min_gpu_power) + self.min_gpu_power\n",
    "        time_gpu = float(self.predictor_time_gpu(time_inputs).detach().numpy())\n",
    "        energy_gpu = float(power_gpu * time_gpu)\n",
    "\n",
    "        return time_cpu, energy_cpu, time_gpu, energy_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa043955-8785-4ca7-9d3f-1c0f94462056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_94/1786070879.py:55: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  time_cpu = float(self.predictor_time_cpu(time_inputs).detach().numpy())\n",
      "/tmp/ipykernel_94/1786070879.py:56: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  energy_cpu = float(power_cpu * time_cpu)\n",
      "/tmp/ipykernel_94/1786070879.py:59: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  time_gpu = float(self.predictor_time_gpu(time_inputs).detach().numpy())\n",
      "/tmp/ipykernel_94/1786070879.py:60: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  energy_gpu = float(power_gpu * time_gpu)\n",
      "/tmp/ipykernel_94/3788453387.py:21: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, tmp_df], ignore_index = True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt_cpu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124me_cpu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt_gpu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124me_gpu\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m trace_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 19\u001b[0m     t_cpu, e_cpu, t_gpu, e_gpu \u001b[38;5;241m=\u001b[39m \u001b[43mlpu_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_service_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSNR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMCS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPRBs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTBS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     tmp_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([[t_cpu, e_cpu, t_gpu, e_gpu]], columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt_cpu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124me_cpu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt_gpu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124me_gpu\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     21\u001b[0m     results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([results_df, tmp_df], ignore_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[3], line 60\u001b[0m, in \u001b[0;36mLPUModels.estimate_service_time\u001b[0;34m(self, snr, mcs, prbs, total_bits)\u001b[0m\n\u001b[1;32m     58\u001b[0m power_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor_power_gpu(power_inputs)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_gpu_power \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_gpu_power) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_gpu_power\n\u001b[1;32m     59\u001b[0m time_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor_time_gpu(time_inputs)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m---> 60\u001b[0m energy_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(power_gpu \u001b[38;5;241m*\u001b[39m time_gpu)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m time_cpu, energy_cpu, time_gpu, energy_gpu\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "    @author:\n",
    "        - Leonardo Lo Schiavo\n",
    "    @affiliation:\n",
    "        - IMDEA Networks institute\n",
    "'''\n",
    "input_file = \"/home/jovyan/data/trace_40BS.csv\"\n",
    "\n",
    "# Load Trace\n",
    "trace_df = pd.read_csv(input_file, sep=\",\", header=0)\n",
    "trace_df.value_counts()\n",
    "\n",
    "# Create an instance of LPU Models\n",
    "lpu_models = LPUModels()\n",
    "\n",
    "# Run inference for each request within the trace\n",
    "results_df = pd.DataFrame(columns = ['t_cpu', 'e_cpu', 't_gpu', 'e_gpu'])\n",
    "for index, row in trace_df.iterrows():\n",
    "    t_cpu, e_cpu, t_gpu, e_gpu = lpu_models.estimate_service_time(row['SNR'], row['MCS'], row['PRBs'], row['TBS'])\n",
    "    tmp_df = pd.DataFrame([[t_cpu, e_cpu, t_gpu, e_gpu]], columns=['t_cpu', 'e_cpu', 't_gpu', 'e_gpu'])\n",
    "    results_df = pd.concat([results_df, tmp_df], ignore_index = True)\n",
    "\n",
    "print(results_df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d62115c-b7dc-42b7-ac08-55099aec7192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/onnx/_internal/exporter.py:130: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch_input = torch.randn(lpu_models.input_size)\n",
    "onnx_program = torch.onnx.dynamo_export(lpu_models.predictor_time_cpu, torch_input)\n",
    "onnx_program.save(\"predictor_time_cpu.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "232110d3-6d23-4bd7-b657-35fa5296cd44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[-0.3379, -0.0991, -0.6082],\n",
       "                      [-0.0297, -0.4052, -0.2961],\n",
       "                      [-0.5679, -0.5233, -0.0720],\n",
       "                      [-0.3518, -0.3192,  0.3252],\n",
       "                      [-0.6820, -0.3859, -0.2634],\n",
       "                      [-0.5616, -0.1591, -0.6823],\n",
       "                      [ 0.4275,  0.2237, -0.0226],\n",
       "                      [ 0.2368,  0.0998, -0.0849],\n",
       "                      [ 0.0101,  0.0264,  0.3062],\n",
       "                      [-0.4623, -0.4166, -0.2218],\n",
       "                      [ 0.2005, -0.3962, -0.2809],\n",
       "                      [-0.5053, -0.3861, -0.8763],\n",
       "                      [-0.2668,  0.0837, -0.2778],\n",
       "                      [-0.3778, -0.2658, -0.1991],\n",
       "                      [-0.0884, -0.5502,  0.2490],\n",
       "                      [-0.0356, -0.6441,  0.2897],\n",
       "                      [-0.0291,  0.0404,  0.3030],\n",
       "                      [-0.5572,  0.3863, -0.0901],\n",
       "                      [-0.5027, -0.4020,  0.1346],\n",
       "                      [-0.5986,  0.0305,  0.4871],\n",
       "                      [-0.2900,  0.4192,  0.0926],\n",
       "                      [-0.4697, -0.0497, -0.1645],\n",
       "                      [-0.0930,  0.2702, -0.3538],\n",
       "                      [ 0.2939, -0.1484, -0.2017],\n",
       "                      [-0.0061, -0.5339, -0.2782],\n",
       "                      [ 0.0681, -0.1849,  0.0781],\n",
       "                      [-0.4768, -0.6968, -0.2491],\n",
       "                      [ 0.3474,  0.0056,  0.0884],\n",
       "                      [ 0.0122,  0.1666, -0.5421],\n",
       "                      [-0.3558,  0.0730,  0.1347],\n",
       "                      [-0.3960,  0.4106, -0.5658],\n",
       "                      [-0.2781, -0.1722, -0.3869],\n",
       "                      [-0.6073, -0.4291, -0.7725],\n",
       "                      [ 0.2519, -0.2234,  0.2716],\n",
       "                      [ 0.2944, -0.0706, -0.1686],\n",
       "                      [-0.0621,  0.1518,  0.3836],\n",
       "                      [-0.1036,  0.3092, -0.2639],\n",
       "                      [-0.5297,  0.1282, -0.0104],\n",
       "                      [-0.6650,  0.3233,  0.1300],\n",
       "                      [-1.0992, -0.0557, -0.1127],\n",
       "                      [-0.3043, -0.5044, -0.6066],\n",
       "                      [-0.0134,  0.0455, -0.1802],\n",
       "                      [-0.2419, -0.1648, -0.5501],\n",
       "                      [-0.8718, -0.5838, -0.1020],\n",
       "                      [ 0.2406,  0.0543, -0.5585],\n",
       "                      [ 0.3420, -0.3187, -0.2118],\n",
       "                      [-0.0945, -0.5114,  0.1532],\n",
       "                      [ 0.4095, -0.5649, -0.1976],\n",
       "                      [-0.3081,  0.0036, -0.2203],\n",
       "                      [-0.3622, -0.4584,  0.3597],\n",
       "                      [-0.0173, -0.0898, -1.0756],\n",
       "                      [ 0.1003,  0.1970, -0.6393],\n",
       "                      [-0.7634,  0.2186, -0.3746],\n",
       "                      [ 0.0689, -0.0700, -0.7548],\n",
       "                      [-0.4504, -0.5834, -0.8725],\n",
       "                      [-0.7193, -0.2443, -0.0464],\n",
       "                      [ 0.1483,  0.0729, -0.4449],\n",
       "                      [-0.4336, -0.4464, -0.1565],\n",
       "                      [-0.1817,  0.3411, -0.4094],\n",
       "                      [ 0.1175, -0.0366, -0.3449],\n",
       "                      [-0.3724, -0.4488, -0.5813],\n",
       "                      [ 0.2841, -0.4218,  0.2891],\n",
       "                      [ 0.2596,  0.0981,  0.1270],\n",
       "                      [-0.4923,  0.1007, -0.5351],\n",
       "                      [-0.5972,  0.3943, -0.4132],\n",
       "                      [-0.4757,  0.0160, -0.9743],\n",
       "                      [-0.4748, -0.5309, -0.1222],\n",
       "                      [-0.6888,  0.2144, -0.2754],\n",
       "                      [ 0.2303, -0.5090,  0.1410],\n",
       "                      [-0.4351,  0.2983, -0.0314],\n",
       "                      [-0.2539, -0.0315, -0.5120],\n",
       "                      [-0.5220, -0.4914, -0.0929],\n",
       "                      [-0.4916, -0.1753, -0.0528],\n",
       "                      [-0.0217, -0.7110, -0.7375],\n",
       "                      [ 0.1670, -0.4427,  0.1094],\n",
       "                      [ 0.2164, -0.4750, -0.0274],\n",
       "                      [-0.4505,  0.0997,  0.2609],\n",
       "                      [-0.4053, -0.3694, -0.3381],\n",
       "                      [-0.0861,  0.1831, -0.1273],\n",
       "                      [ 0.0432,  0.1476, -0.2387],\n",
       "                      [ 0.4209, -0.4640,  0.0719],\n",
       "                      [ 0.1590,  0.3399, -0.2968],\n",
       "                      [-0.2258,  0.1586, -0.5007],\n",
       "                      [-0.5635,  0.1987,  0.2129],\n",
       "                      [-0.4792, -0.3118,  0.0563],\n",
       "                      [-0.2855, -0.7135, -0.1835],\n",
       "                      [-0.6971, -0.5626,  0.0040],\n",
       "                      [ 0.0873, -0.2178, -0.2755],\n",
       "                      [ 0.0129, -0.8643, -0.1337],\n",
       "                      [-0.9617, -0.3602, -0.1351],\n",
       "                      [-0.6698, -0.2152,  0.0169],\n",
       "                      [-0.1058, -0.5644,  0.1133],\n",
       "                      [ 0.1850,  0.2450,  0.0422],\n",
       "                      [-0.5046, -0.0426,  0.4611],\n",
       "                      [-0.3221,  0.0396,  0.2010],\n",
       "                      [ 0.1265, -0.5867,  0.4589],\n",
       "                      [ 0.1474, -0.3222, -0.2833],\n",
       "                      [-0.4564,  0.1448,  0.0648],\n",
       "                      [ 0.0606,  0.1334, -0.0265],\n",
       "                      [-0.0680, -0.0383,  0.2399],\n",
       "                      [-0.4985, -0.2436, -0.9236],\n",
       "                      [-0.1016,  0.3276, -0.1554],\n",
       "                      [-0.3047, -0.3515, -0.0888],\n",
       "                      [ 0.2328, -0.2042, -0.5012],\n",
       "                      [-0.1602,  0.2073,  0.2247],\n",
       "                      [-0.1885, -0.7921, -0.1489],\n",
       "                      [-0.1460, -0.9099, -0.4423],\n",
       "                      [-0.3165,  0.1476, -0.6788],\n",
       "                      [-0.1433, -0.0452, -0.3537],\n",
       "                      [ 0.0576, -0.5710,  0.0462],\n",
       "                      [-0.9048,  0.0779, -0.1580],\n",
       "                      [ 0.1794, -0.5074,  0.1608],\n",
       "                      [ 0.3500,  0.1909, -0.0358],\n",
       "                      [ 0.0972, -0.6772,  0.1018],\n",
       "                      [ 0.2417, -0.0490, -0.2888],\n",
       "                      [-0.2359, -0.4312, -0.4406],\n",
       "                      [-0.0567, -0.3784, -0.0625],\n",
       "                      [-0.3913, -0.0209, -0.2914],\n",
       "                      [-0.5476, -0.0087, -0.2748],\n",
       "                      [ 0.3373,  0.0067, -0.4221],\n",
       "                      [-0.2194, -0.4757, -0.9933],\n",
       "                      [-0.4532,  0.2803, -0.3173],\n",
       "                      [-0.6195, -0.7553, -0.7792],\n",
       "                      [-0.2403,  0.0270,  0.3934],\n",
       "                      [ 0.3400, -0.3064, -0.3191],\n",
       "                      [-0.2059,  0.0053,  0.2613],\n",
       "                      [ 0.0153,  0.1208,  0.0289],\n",
       "                      [ 0.2019, -0.0725, -0.8593]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 0.0421,  0.0040,  0.0202, -0.3368,  0.0572,  0.0546, -0.6584, -0.4168,\n",
       "                      -0.3452,  0.0288, -0.5073,  0.0371,  0.0325,  0.0242, -0.2540, -0.2920,\n",
       "                      -0.3307,  0.0445, -0.0965, -0.4299, -0.5113,  0.0489, -0.2398, -0.2955,\n",
       "                      -0.3100, -0.3852,  0.0469, -0.4441, -0.1804, -0.1492, -0.1004,  0.0151,\n",
       "                       0.0596, -0.5353, -0.3492, -0.5113, -0.2356,  0.0524, -0.0791,  0.1086,\n",
       "                       0.0319, -0.0632, -0.1361,  0.0883, -0.4412, -0.3475, -0.2043, -0.4178,\n",
       "                      -0.0287, -0.5342,  0.0046, -0.3749,  0.0848, -0.0783,  0.0474,  0.0693,\n",
       "                      -0.2319, -0.2806, -0.2600, -0.1760,  0.0188, -0.6589, -0.5400,  0.0528,\n",
       "                       0.0497,  0.0435,  0.0348,  0.0701, -0.3946,  0.0419,  0.0222, -0.3643,\n",
       "                      -0.1635, -0.0380, -0.2942, -0.2221, -0.3216,  0.0306, -0.1115, -0.2741,\n",
       "                      -0.5228, -0.5009, -0.0550, -0.4565, -0.0661,  0.0039,  0.0583, -0.1295,\n",
       "                      -0.0417,  0.0639,  0.0401, -0.1626, -0.4917, -0.4748, -0.1749, -0.6373,\n",
       "                      -0.1480, -0.0195, -0.2580, -0.2711,  0.0553, -0.2493,  0.0056, -0.2686,\n",
       "                      -0.3203,  0.0013,  0.0034,  0.0178, -0.0013, -0.2023,  0.0931, -0.4297,\n",
       "                      -0.6329, -0.2251, -0.3008,  0.0075, -0.0078,  0.0229,  0.0349, -0.3608,\n",
       "                      -0.0015, -0.4356,  0.0680, -0.3970, -0.3403, -0.2637, -0.1932, -0.2610])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-0.0567,  0.0694, -0.0402,  ..., -0.0278,  0.0412, -0.0103],\n",
       "                      [-0.0315, -0.0292, -0.0815,  ..., -0.0312,  0.0373, -0.0881],\n",
       "                      [-0.0729, -0.0552, -0.0547,  ..., -0.0389,  0.0642,  0.0439],\n",
       "                      ...,\n",
       "                      [-0.0235, -0.1658, -0.0703,  ..., -0.0898, -0.0441, -0.2346],\n",
       "                      [-0.0283,  0.0112, -0.0782,  ..., -0.0683,  0.0428, -0.0317],\n",
       "                      [ 0.0103, -0.1298,  0.0316,  ..., -0.0401,  0.0316, -0.0578]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([-5.5401e-02, -7.9203e-02, -3.2315e-02, -5.1509e-02, -9.1403e-02,\n",
       "                      -4.1657e-02, -1.7987e-02, -6.4516e-02, -5.7390e-02, -8.0908e-02,\n",
       "                      -8.6530e-02, -3.9556e-02, -3.7541e-02, -1.0208e-01, -1.3461e-02,\n",
       "                      -5.4113e-02, -8.0401e-02, -2.8648e-02, -1.3763e-02, -5.0516e-02,\n",
       "                      -6.5298e-02, -4.6401e-02, -1.5962e-02, -9.0065e-02, -1.3971e-01,\n",
       "                      -8.3629e-02, -8.1492e-02, -6.0604e-02, -9.6628e-02, -1.0794e-01,\n",
       "                      -1.7047e-02, -5.4683e-02, -4.0326e-02, -1.0002e-01, -2.1370e-02,\n",
       "                      -7.3488e-02, -1.2184e-01, -4.1453e-02, -3.2359e-02, -5.3664e-02,\n",
       "                      -6.6940e-02, -2.2953e-02, -1.4165e-01, -8.3917e-02, -7.7774e-02,\n",
       "                      -2.3052e-02, -8.5382e-02, -1.9876e-02, -4.2891e-02, -6.9848e-02,\n",
       "                      -5.3536e-04, -1.7711e-02, -6.0613e-02, -2.4804e-02, -1.0144e-01,\n",
       "                      -3.2301e-02, -2.3900e-02, -3.4997e-02, -4.4042e-02, -4.7767e-02,\n",
       "                      -3.5197e-02, -2.4132e-02, -9.8852e-02, -4.8419e-02, -6.8034e-02,\n",
       "                      -1.2628e-01, -2.6429e-03, -7.9601e-02, -1.0403e-02, -8.7664e-02,\n",
       "                      -2.2936e-02, -9.7291e-02, -9.2860e-02, -7.4750e-02, -4.7278e-02,\n",
       "                      -5.8494e-02, -5.1391e-02, -2.2884e-02, -4.4151e-02, -1.5766e-01,\n",
       "                      -3.2417e-02, -5.4154e-02, -6.1796e-02, -6.2485e-02, -4.0909e-02,\n",
       "                      -2.3463e-02, -6.2672e-02, -6.7960e-02, -4.9654e-02, -6.9190e-02,\n",
       "                      -6.0481e-02, -3.9965e-02, -7.7403e-02, -5.1557e-02, -5.9903e-02,\n",
       "                      -7.5140e-02, -6.1324e-02, -5.2229e-02, -7.5986e-02, -7.3454e-02,\n",
       "                      -2.4719e-05, -3.1155e-02, -3.2942e-02, -6.1567e-02, -3.4905e-02,\n",
       "                      -1.7097e-01, -7.3379e-02, -2.2046e-02, -7.5303e-02, -7.0228e-02,\n",
       "                      -3.7273e-02, -7.2206e-02, -8.0148e-02, -6.3046e-02, -3.9756e-02,\n",
       "                      -3.5868e-02, -1.2925e-01, -3.1896e-02, -2.9795e-02, -5.6720e-02,\n",
       "                      -4.4600e-02, -3.4530e-02, -9.9914e-02, -6.4887e-02, -5.3717e-02,\n",
       "                      -6.3792e-02, -2.1719e-02, -2.4067e-02])),\n",
       "             ('fc3.weight',\n",
       "              tensor([[-9.4472e-04, -6.9069e-02, -1.7678e-02,  3.2285e-02, -9.7620e-03,\n",
       "                       -2.0723e-02,  1.8138e-02, -1.3953e-02,  1.0893e-02,  4.0813e-02,\n",
       "                       -2.0951e-02,  3.0286e-02,  1.8741e-02, -1.3606e-02, -2.9406e-03,\n",
       "                        4.4321e-03,  2.3670e-02, -3.1947e-03, -1.8683e-02, -2.3657e-02,\n",
       "                       -1.5852e-02,  4.9414e-03,  2.2332e-02,  1.1629e-02,  7.0856e-03,\n",
       "                       -6.7967e-02, -6.2983e-02, -5.0491e-02,  9.8682e-03,  3.6917e-02,\n",
       "                       -2.8813e-02, -2.3894e-02, -2.4320e-02,  2.3158e-02, -3.5091e-03,\n",
       "                       -4.4217e-02, -2.7228e-02, -2.6112e-02,  3.9488e-02,  5.0691e-03,\n",
       "                       -3.0696e-02, -1.8845e-02,  2.1415e-02,  4.5391e-02, -3.2201e-03,\n",
       "                       -3.0922e-02, -2.4426e-02,  5.5656e-02,  2.8979e-02, -2.9970e-02,\n",
       "                       -3.2293e-03, -8.1029e-04,  5.5946e-03,  1.7747e-03, -2.2584e-02,\n",
       "                       -3.1053e-02,  4.8833e-03,  6.2639e-02, -4.9598e-04, -1.4269e-02,\n",
       "                       -6.0199e-03, -2.4835e-02, -2.1469e-02, -2.8435e-02,  6.4463e-02,\n",
       "                       -1.6488e-02,  7.7192e-03, -2.9611e-02,  6.7787e-03, -7.9363e-02,\n",
       "                       -2.5145e-02,  9.3800e-04, -2.0130e-02, -3.1850e-03, -1.0121e-02,\n",
       "                        1.1006e-02,  1.6811e-02, -8.6276e-03, -9.5915e-03, -2.0648e-03,\n",
       "                       -2.8617e-02,  1.9200e-02,  3.8857e-03, -9.6125e-03, -2.4081e-02,\n",
       "                       -2.0597e-02, -1.5866e-03, -4.7322e-03, -3.0763e-02, -4.9895e-02,\n",
       "                        3.3990e-03,  5.3702e-03,  1.1713e-03,  1.7206e-02, -3.6464e-02,\n",
       "                        2.0109e-02, -1.5555e-02, -2.8845e-03, -2.5549e-02, -6.9859e-02,\n",
       "                       -2.1767e-05,  3.1599e-02, -2.6857e-02,  2.1587e-02,  1.1154e-02,\n",
       "                        3.4111e-02,  1.4681e-02, -1.0869e-02, -3.2646e-04,  3.8204e-03,\n",
       "                       -2.2196e-02, -1.8918e-02, -2.1613e-02,  1.6123e-02, -2.8414e-02,\n",
       "                        1.1865e-02, -2.1452e-02,  1.9521e-02, -1.4732e-02, -1.7273e-03,\n",
       "                        2.9806e-02, -3.1052e-02, -2.7395e-02, -1.2093e-02, -2.4249e-02,\n",
       "                        9.4618e-04, -1.7225e-02, -2.8872e-02]])),\n",
       "             ('fc3.bias', tensor([1.3845]))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('/home/jovyan/data/predictor_time_cpu.pyt', map_location=\"cpu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
